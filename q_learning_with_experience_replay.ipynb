{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q_learning_with_experience_replay.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkAMYMtwWavNYPoUAnvBtc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iramuk-ganh/rl/blob/main/q_learning_with_experience_replay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWRUhH_vJPfC",
        "outputId": "f3977211-233b-42a1-e43d-0f5107fecea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155229 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.10_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.10) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "jwFsg6TnJTxh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = np.max([self.get_qvalue(state, a) for a in possible_actions])\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        q_value = self.get_qvalue(state, action)\n",
        "        q_value = (1-learning_rate) * q_value + learning_rate * (reward + gamma * self.get_value(next_state))\n",
        "\n",
        "        self.set_qvalue(state, action, q_value )\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        best_action_index = np.argmax([self.get_qvalue(state, a) for a in possible_actions])                         \n",
        "\n",
        "        return possible_actions[best_action_index]\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.get_best_action).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        #With probability self.epsilon, we should take a random action\n",
        "        choice = np.random.choice([0, 1], p=[epsilon, 1-epsilon])\n",
        "\n",
        "        if choice:#best_action\n",
        "          return self.get_best_action(state)\n",
        "\n",
        "        else:\n",
        "          return np.random.choice(possible_actions)\n"
      ],
      "metadata": {
        "id": "GO2uLC5fJXGO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "CgW9E5sHJog8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ReplayBuffer"
      ],
      "metadata": {
        "id": "waFqYVtONmgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size):\n",
        "        \"\"\"\n",
        "        Create Replay buffer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        size: int\n",
        "            Max number of transitions to store in the buffer. When the buffer\n",
        "            overflows the old memories are dropped.\n",
        "\n",
        "        Note: for this assignment you can pick any data structure you want.\n",
        "              If you want to keep it simple, you can store a list of tuples of (s, a, r, s') in self._storage\n",
        "              However you may find out there are faster and/or more memory-efficient ways to do so.\n",
        "        \"\"\"\n",
        "        self._storage = deque([])\n",
        "        self._maxsize = size\n",
        "\n",
        "        # OPTIONAL: YOUR CODE\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._storage)\n",
        "\n",
        "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
        "        '''\n",
        "        Make sure, _storage will not exceed _maxsize. \n",
        "        Make sure, FIFO rule is being followed: the oldest examples has to be removed earlier\n",
        "        '''\n",
        "        data = (obs_t, action, reward, obs_tp1, done)\n",
        "        self._storage.append(data)\n",
        "\n",
        "        # add data to storage\n",
        "        if(self.__len__() > self._maxsize):\n",
        "          self._storage.popleft()\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Sample a batch of experiences.\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size: int\n",
        "            How many transitions to sample.\n",
        "        Returns\n",
        "        -------\n",
        "        obs_batch: np.array\n",
        "            batch of observations\n",
        "        act_batch: np.array\n",
        "            batch of actions executed given obs_batch\n",
        "        rew_batch: np.array\n",
        "            rewards received as results of executing act_batch\n",
        "        next_obs_batch: np.array\n",
        "            next set of observations seen after executing act_batch\n",
        "        done_mask: np.array\n",
        "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
        "            the end of an episode and 0 otherwise.\n",
        "        \"\"\"\n",
        "        #indxes = <YOUR CODE: randomly generate batch_size integers to be used as indexes of samples>\n",
        "        trajectory_numbers = [np.random.choice(range(self.__len__())) for t in range(batch_size)]\n",
        "\n",
        "        # collect <s,a,r,s',done> for each index\n",
        "        obs_batch = []\n",
        "        action_batch = []\n",
        "        reward_batch = []\n",
        "        next_obs_batch = []\n",
        "        done_batch = []\n",
        "\n",
        "        for i in trajectory_numbers:\n",
        "          obs_batch.append(self._storage[i][0])#storage is a list of tuples, each tuple being(s,a,r,s',done).Each tuple is a trajectory and storage is a collection of sequential trajectories\n",
        "          action_batch.append(self._storage[i][1])\n",
        "          reward_batch.append(self._storage[i][2])\n",
        "          next_obs_batch.append(self._storage[i][3])\n",
        "          done_batch.append(self._storage[i][4])\n",
        "\n",
        "        return (\n",
        "            np.array( obs_batch ),\n",
        "            np.array( action_batch ),\n",
        "            np.array( reward_batch ),\n",
        "            np.array( next_obs_batch ),\n",
        "            np.array( done_batch),\n",
        "        )"
      ],
      "metadata": {
        "id": "f7GwL5N7JajQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay = ReplayBuffer(2)\n",
        "obj1 = tuple(range(5))\n",
        "obj2 = tuple(range(5, 10))\n",
        "replay.add(*obj1)\n",
        "assert replay.sample(1)==obj1, \"If there's just one object in buffer, it must be retrieved by buf.sample(1)\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay._storage)==2, \"Please make sure __len__ methods works as intended.\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay._storage)==2, \"When buffer is at max capacity, replace objects instead of adding new ones.\"\n",
        "assert tuple(np.unique(a) for a in replay.sample(100))==obj2\n",
        "replay.add(*obj1)\n",
        "assert max(len(np.unique(a)) for a in replay.sample(100))==2\n",
        "replay.add(*obj1)\n",
        "assert tuple(np.unique(a) for a in replay.sample(100))==obj1\n",
        "print (\"Success!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkdjF97NJ5I7",
        "outputId": "8dc96a32-acb9-4de8-a79a-2ca71df4c1d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Now let's use this buffer to improve training"
      ],
      "metadata": {
        "id": "QuvZYZTFMA_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "😌1 episode means 1 game"
      ],
      "metadata": {
        "id": "7yU8d9tBNGyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "XjBgwElKLYAo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v3\")\n",
        "no_of_actions = env.action_space.n"
      ],
      "metadata": {
        "id": "OWWXOLAFMQ5w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_and_train_with_replay(env, agent, replay=None,\n",
        "                               t_max=10**4, replay_batch_size=32):\n",
        "    \"\"\"\n",
        "    This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\n",
        "    :param replay: ReplayBuffer where agent can store and sample (s,a,r,s',done) tuples.\n",
        "        If None, do not use experience replay\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # get agent to pick action given state s\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "        # update agent on current transition. Use agent.update\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        if replay is not None:\n",
        "            # store current <s,a,r,s'> transition in buffer\n",
        "            replay.add(s, a, r, next_s, done)\n",
        "\n",
        "            # sample replay_batch_size random transitions from replay,\n",
        "            # then update agent on each of them in a loop\n",
        "            s_, a_, r_, next_s_, done_ = replay.sample(replay_batch_size)\n",
        "            for i in range(replay_batch_size):\n",
        "                agent.update(s_[i], a_[i], r_[i], next_s_[i])\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "metadata": {
        "id": "73Ac1qSTMf0d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "mL5NtSrNP9qL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two agents: first will use experience replay, second will not.\n",
        "\n",
        "agent_baseline = QLearningAgent(\n",
        "    alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "    get_legal_actions=lambda s: range(no_of_actions))\n",
        "\n",
        "agent_replay = QLearningAgent(\n",
        "    alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "    get_legal_actions=lambda s: range(no_of_actions))\n",
        "\n",
        "replay = ReplayBuffer(1000)"
      ],
      "metadata": {
        "id": "4KAZsYpsPvv1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8Sc6zCP7PwkD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_replay, rewards_baseline = [], []\n",
        "\n",
        "for i in range(1000):\n",
        "    rewards_replay.append(\n",
        "        play_and_train_with_replay(env, agent_replay, replay))\n",
        "    rewards_baseline.append(\n",
        "        play_and_train_with_replay(env, agent_baseline, replay=None))\n",
        "\n",
        "    agent_replay.epsilon *= 0.99\n",
        "    agent_baseline.epsilon *= 0.99\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('Baseline : eps =', agent_replay.epsilon,\n",
        "              'mean reward =', np.mean(rewards_baseline[-10:]))\n",
        "        print('ExpReplay: eps =', agent_baseline.epsilon,\n",
        "              'mean reward =', np.mean(rewards_replay[-10:]))\n",
        "        plt.plot(moving_average(rewards_replay), label='exp. replay')\n",
        "        plt.plot(moving_average(rewards_baseline), label='baseline')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EZh0WrPBQpdA",
        "outputId": "79d45cc3-605b-423f-ffd0-ce7c94d2848f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline : eps = 2.9191091959171894e-05 mean reward = 7.2\n",
            "ExpReplay: eps = 2.9191091959171894e-05 mean reward = 6.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from submit import submit_experience_replay\n",
        "submit_experience_replay(rewards_replay, rewards_baseline, 'yonghangaashma7@gmail.com', 'Yb0rlhECn7IagnFf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii4lQGrdRHku",
        "outputId": "f6a97e9b-2f23-417f-8136-7828781803b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ]
        }
      ]
    }
  ]
}